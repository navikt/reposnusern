# ğŸ•µï¸ reposnusern (POC)

**reposnusern** er et verktÃ¸y for Ã¥ analysere GitHub-repositorier i en organisasjon â€“ med nysgjerrighet, struktur og en dÃ¦sj AI.

## ğŸ¯ Ambisjon

MÃ¥let med dette prosjektet er Ã¥ lage et fleksibelt og utvidbart analyseverktÃ¸y for utviklingsmiljÃ¸er som Ã¸nsker innsikt i kodebasen sin. Prosjektet utvikles stegvis:

### 1. Datainnhenting

- Henter metadata, sprÃ¥kbruk, Dockerfiles og dependency-filer fra alle repoer i en GitHub-organisasjon.
- Data lagres i en relasjonsdatabase (SQLite i PoC).
- Bruker JSON-filer som mellomlagring for Ã¥ redusere GitHub API-bruk.
- KjÃ¸res periodisk (f.eks. via cron-jobb).

### 2. AnalyseverktÃ¸y

- KjÃ¸rer regelbaserte analyser av:
  - Dockerfiles (best practices og sikkerhet)
  - Dependency-filer (rammeverk og versjonsbruk per sprÃ¥k)
  - SprÃ¥kstatistikk
- Resultater lagres i databasen for effektiv spÃ¸rring og videre bruk.

### 3. TilgjengeliggjÃ¸ring av data

- Tilbyr en enkel API for Ã¥ hente ut data og analyseresultater.
- Tanken er at dataene kan brukes av:
  - Andre Go-programmer
  - Jupyter-notebooks
  - VisualiseringsverktÃ¸y som Power BI, Metabase eller Grafana

### Teknologier og oppsett

- ğŸ§  SprÃ¥k: Go
- ğŸ—ƒï¸ Database: SQLite (sqlc brukt for typesikker tilgang)
- ğŸ“¦ Strukturelt monorepo â€“ men med tydelig inndeling

## ğŸ§ª PoC-status

### 1. Datainnhenting

Proof-of-Concept bruker fÃ¸lgende:
- `go + sqlc + PostgreSQL` 
- GitHub-API med mellomlagring i JSON
- StÃ¸tte for:
  - Repo-metadata og sprÃ¥k
  - Dockerfiles og dependency-filer
  - CI-konfigurasjon, README og sikkerhetsfunksjoner

Dette gir et godt grunnlag for Ã¥ bygge videre analyser, inkludert rammeverksdeteksjon basert pÃ¥ sprÃ¥k og filstruktur.

### 2. Analyse
TODO

### 3. TilgjengeliggjÃ¸ring
TODO (akkurat nÃ¥ kan man hente det i en posgresdb.)

## ğŸ“ Prosjektstruktur
```
repo-analyzer/
reposnusern/
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ fetch/ # Henter og lagrer data fra GitHub
â”‚   â”œâ”€â”€ import/ # Importerer JSON-data til database
â”‚   â”œâ”€â”€ migrate/ # KjÃ¸r initial migrering av PostgreSQL
â”‚   â””â”€â”€ analyze/ # Fremtidig analyser og spÃ¸rringer
â”‚
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ fetcher/ # GitHub-klient og mellomlagring
â”‚   â”œâ”€â”€ analyzer/ # Analyse av Dockerfiles og dependencies
â”‚   â”œâ”€â”€ storage/ # sqlc-basert tilgang til databasen
â”‚   â”œâ”€â”€ models/ # Delte datastrukturer
â”‚   â””â”€â”€ config/ # HÃ¥ndtering av konfig og secrets
â”‚
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ queries/ # sqlc-spÃ¸rringer
â”‚   â””â”€â”€ schema.sql # PostgreSQL-schema
â”‚
â”œâ”€â”€ data/ # Midlertidige JSON-filer
â”œâ”€â”€ sqlc.yaml # sqlc-konfigurasjon
â”œâ”€â”€ go.mod / go.sum
â””â”€â”€ README.md
```

## KjÃ¸ring

### Json henting

For Ã¥ hente data fra GitHub mÃ¥ du angi organisasjonsnavn og et gyldig GitHub-token som miljÃ¸variabler:

```
export ORG=navikt
export GITHUB_TOKEN=<din_token>
go run ./cmd/fetch
```

Alternativt
```
# Bygg containeren
podman build -t reposnusnern .

# KjÃ¸r med nÃ¸dvendige miljÃ¸variabler og bind-mount for Ã¥ se utdata
podman run --rm \
  -e ORG=dinorg \
  -e GITHUB_TOKEN=ghp_dintokenher \
  -e REPOSNUSERDEBUG=true \
  -v "$PWD/data":/data \
  reposnusnern

```

Dette scriptet vil:
- en rÃ¥ oversikt over alle repoer (data/navikt_repos_raw_dump.json)
- detaljert analyse av ikke-arkiverte repoer (data/navikt_analysis_data.json)

Merk: GitHub har en grense pÃ¥ 5000 API-kall per time for autentiserte brukere. Scriptet hÃ¥ndterer dette automatisk ved Ã¥ pause og fortsette nÃ¥r grensen er nÃ¥dd.

### Migrering til PostgresSQL

Eksempel:

```
export POSTGRES_DSN="postgres://<bruker>:<passord>@<fqdn>:5432/reposnusern?sslmode=require"
go run ./cmd/migrate
```

## TODO

- [ ] ğŸ” Hindre at passord og secrets utilsiktet havner i logger
- [ ] ğŸŒ Bygge et lite Go-API for noen nyttige queries
- [ ] â˜ï¸ GjÃ¸re klart for K8s-deploy (config, secrets, jobs)
- [ ] âœ… Legge til noen enkle tester (det var jo bare en PoC ğŸ˜…)
- [ ] ğŸ§¹ Refaktorering og deling av logikk
- [ ] Oppdatere schema sÃ¥ vi tar vare pÃ¥ dato vi har hentet informasjonen fra. (SÃ¥ vi kan ta vare pÃ¥ trenden.)
- [ ] ğŸ“Š Mer visuell analyse og rapportering i neste steg

## Annen inspirasjon
 - [Fuck it, ship it - Stine MÃ¸lgaard og Jacob BÃ¸tter](https://fuckitshipit.dk/)
 - [Codin' Dirty - Carson Gross](https://htmx.org/essays/codin-dirty/)

## ğŸ¤– ErklÃ¦ring om bruk av generativ KI

Under utviklingen av dette innholdet har forfatter(e) benyttet generativ KI â€“ inkludert M365 Copilot og ChatGPT â€“ til Ã¥ omformulere og effektivisere tekst og kode. Alt innhold er deretter gjennomgÃ¥tt og en del redigert manuelt. 
