# ğŸ•µï¸ reposnusern (POC)

**reposnusern** er et verktÃ¸y for Ã¥ analysere GitHub-repositorier i en organisasjon â€“ med nysgjerrighet, struktur og en dÃ¦sj AI.

## ğŸ¯ Ambisjon

MÃ¥let med dette prosjektet er Ã¥ lage et fleksibelt og utvidbart analyseverktÃ¸y for utviklingsmiljÃ¸er som Ã¸nsker innsikt i kodebasen sin. Prosjektet utvikles stegvis:

### Datainnhenting

- Henter metadata, sprÃ¥kbruk, Dockerfiles og dependency-filer fra alle repoer i en GitHub-organisasjon.
- Data lagres i en relasjonsdatabase (PostgreSQL).
- KjÃ¸res periodisk (f.eks. via cron-jobb).

### Teknologier og oppsett

- ğŸ§  SprÃ¥k: Go
- ğŸ—ƒï¸ Database: PostgreSQL (sqlc brukt for typesikker tilgang)
- ğŸ“¦ Strukturelt monorepo â€“ men med tydelig inndeling

## ğŸ§ª PoC-status

Proof-of-Concept bruker fÃ¸lgende:
- `go + sqlc + PostgreSQL` 
- GitHub-API med mellomlagring i JSON
- StÃ¸tte for:
  - Repo-metadata og sprÃ¥k
  - Dockerfiles og dependency-filer
  - CI-konfigurasjon, README og sikkerhetsfunksjoner
  - SBOM

Dette gir et godt grunnlag for Ã¥ bygge videre analyser, inkludert rammeverksdeteksjon basert pÃ¥ sprÃ¥k og filstruktur.


## ğŸ“ Prosjektstruktur
```
reposnusern/
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ fetch/      # Henter og lagrer data fra GitHub
â”‚   â”œâ”€â”€ migrate/    # Importerer JSON-data til PostgreSQL
â”‚   â””â”€â”€ full/       # KjÃ¸rer fÃ¸rst fetch og sÃ¥ migrate.
â”‚
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ fetcher/    # GitHub-klient og mellomlagring
â”‚   â”œâ”€â”€ dbwriter/   # Analyse av Dockerfiles og dependencies
â”‚   â”œâ”€â”€ storage/    # sqlc-basert tilgang til databasen
â”‚   â””â”€â”€ parser/     # Parsing av filer
â”‚
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ queries/    # sqlc-spÃ¸rringer
â”‚   â””â”€â”€ schema.sql  # PostgreSQL-schema
â”‚
â”œâ”€â”€ data/           # Midlertidige JSON-filer
â”œâ”€â”€ sqlc.yaml       # sqlc-konfigurasjon
â”œâ”€â”€ go.mod / go.sum # Go-moduldefinisjoner
â”œâ”€â”€ Dockerfile      # Bygging og kjÃ¸ring i container
â””â”€â”€ README.md
```

## KjÃ¸ring

For Ã¥ hente data fra GitHub mÃ¥ du angi organisasjonsnavn og et gyldig GitHub-token som miljÃ¸variabler:

```
# Bygg containeren
podman build -t reposnusnern .

# KjÃ¸r med nÃ¸dvendige miljÃ¸variabler og bind-mount for Ã¥ se utdata
podman run --rm \
  -e ORG=dinorg \
  -e GITHUB_TOKEN=ghp_dintokenher \
  -e POSTGRES_DSN="postgres://<bruker>:<passord>@<fqdn>:5432/reposnusern?sslmode=require" \
  -e REPOSNUSERDEBUG=true \
  -e REPOSNUSERARCHIVE=false \
  -v "$PWD/data":/data \
  reposnusnern

```

REPOSNUSERDEBUG=true gjÃ¸r at maks 10 repos blir hentet, for Ã¥ teste ut uten Ã¥ spamme github apiet.
REPOSNUSERARCHIVE=true vil sette at arkiverte repos ogsÃ¥ blir hentet, ellers blir kun aktive hentet.

Merk: GitHub har en grense pÃ¥ 5000 API-kall per time for autentiserte brukere. Koden hÃ¥ndterer dette automatisk ved Ã¥ pause og fortsette nÃ¥r grensen er nÃ¥dd.

## ğŸ’ª Testing

Prosjektet har stÃ¸tte for bÃ¥de enhetstester og integrasjonstester:

### Enhetstester

* Skrevet med [Ginkgo](https://onsi.github.io/ginkgo/) og [Gomega](https://onsi.github.io/gomega/) for BDD-stil
* Bruker `mockery` for generering av mocks
* Testbare komponenter bruker interfaces og dependency injection der det gir mening

KjÃ¸r enhetstester:

```bash
make unit
```

### Integrasjonstester

* Ligger i `test/`-mappen
* KjÃ¸res mot en ekte PostgreSQL-database i container via [testcontainers-go](https://github.com/testcontainers/testcontainers-go)
* Initialiseres med `schema.sql`

KjÃ¸r integrasjonstester:

```bash
make integration
```

> Merk: Du mÃ¥ ha stÃ¸tte for Podman eller Docker for Ã¥ kjÃ¸re integrasjonstestene.

### Samlet testkjÃ¸ring og linting

```bash
make test     # KjÃ¸rer bÃ¥de unit og integration (hvis mulig)
make ci       # KjÃ¸rer hygiene + test: tidy, vet, lint, test
```


## TODO

- [x] Parsing av forskjellige dependency filer
- [x] OgsÃ¥ hente REST API endpoints for software bill of materials (SBOM)
- [x] ğŸ” Hindre at passord og secrets utilsiktet havner i logger
- [x] âœ… Legge til noen enkle tester
- [x] ğŸ§¹ Refaktorering og deling av logikk
- [ ] GjÃ¸re om alle testene til Ginko/gomega
- [ ] Bedre logging
- [x] â˜ï¸ GjÃ¸re klart for K8s-deploy (config, secrets, jobs)
- [ ] SÃ¸rge for at GraphQL versjonen ogsÃ¥ parser lenger ned enn toppnivÃ¥ mappen.
- [x] Vurdere om sbom direkte har fjernet behovet for dependency files
- [ ] Optimalisering
  - [ ] Lage en bulk insert til db for relevante objekter
  - [x] Fortsette Ã¥ optimalisere pÃ¥ minne
- [x] Forbedre dockerfile features parseren for mer info
- [ ] Oppdatere schema sÃ¥ vi tar vare pÃ¥ dato vi har hentet informasjonen fra. (SÃ¥ vi kan ta vare pÃ¥ trenden.)

## Annen inspirasjon
 - [Fuck it, ship it - Stine MÃ¸lgaard og Jacob BÃ¸tter](https://fuckitshipit.dk/)
 - [Codin' Dirty - Carson Gross](https://htmx.org/essays/codin-dirty/)

## Benchmark
Med ca 1600 repos:

```
{"time":"2025-06-09T19:40:24.731770893Z","level":"INFO","msg":"ğŸ“Š Minnebruk","alloc":"1.1 GiB","totalAlloc":"3.6 GiB","sys":"1.4 GiB","numGC":38}
{"time":"2025-06-09T19:40:24.73178756Z","level":"INFO","msg":"âœ… Ferdig!","varighet":"42m47.74474624s"}
```

## ğŸ¤– ErklÃ¦ring om bruk av generativ KI

Under utviklingen av dette innholdet har forfatter(e) benyttet generativ KI â€“ inkludert M365 Copilot og ChatGPT â€“ til Ã¥ omformulere og effektivisere tekst og kode. Alt innhold er deretter gjennomgÃ¥tt og en del redigert manuelt. 
